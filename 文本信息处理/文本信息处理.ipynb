{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import jieba\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "infodf = pd.read_csv('infoall.csv').drop('Unnamed: 0.1',axis = 1).set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  加载停用词列表\n",
    "def load_stopword():\n",
    "    f_stop = open('hit_stopwords.txt', encoding='utf-8')  # 自己的中文停用词表\n",
    "    sw = [line.strip() for line in f_stop]  # strip() 方法用于移除字符串头尾指定的字符（默认为空格）\n",
    "    f_stop.close()\n",
    "    return sw\n",
    "\n",
    "# 中文分词并且去停用词\n",
    "def seg_word(sentence):\n",
    "    file_userDict = 'hit_stopwords.txt'  # 自定义的词典\n",
    "    jieba.load_userdict(file_userDict)\n",
    "\n",
    "    sentence_seged = jieba.cut(sentence.strip(),cut_all=False)\n",
    "    stopwords = load_stopword()\n",
    "    outstr = ''\n",
    "    for word in sentence_seged:\n",
    "        if word not in stopwords:\n",
    "            if word != '/t':\n",
    "                outstr += word\n",
    "                outstr += \" \"\n",
    "    return outstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5432/5432 [02:13<00:00, 40.60it/s]\n"
     ]
    }
   ],
   "source": [
    "f = open('sentences.txt','w')\n",
    "for stocknum , stockinfo in tqdm(infodf.iterrows(),total=infodf.shape[0]):\n",
    "    f.write(str(stockinfo['name']).strip('nan') + ' ')\n",
    "    f.write(str(stockinfo['shortname']).strip('nan')+ ' ')\n",
    "    f.write(str(stockinfo['prename']).strip('nan')+ ' ')\n",
    "    f.write(seg_word(str(stockinfo['operation'])))\n",
    "    f.write(seg_word(str(stockinfo['operation_scope'])))\n",
    "    f.write(seg_word(str(stockinfo['introduction'])))\n",
    "    f.write(str(stockinfo['legal_representative']).strip('nan')+ ' ')\n",
    "    f.write(str(stockinfo['actual_controller']).strip('nan')+ ' ')\n",
    "    f.write(str(stockinfo['office']).strip('nan')+ ' ')\n",
    "    f.write(str(stockinfo.name).strip('nan'))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = word2vec.Text8Corpus(\"sentences.txt\")\n",
    "model=gensim.models.Word2Vec(sentences,sg=1,window=10,min_count=2,negative=3,sample=0.001,hs=1,workers=4)\n",
    "#sg=1是skip—gram算法，对低频词敏感，默认sg=0为CBOW算法\n",
    "#size是神经网络层数，值太大则会耗内存并使算法计算变慢，一般值取为100到200之间。\n",
    "#window是句子中当前词与目标词之间的最大距离，3表示在目标词前看3-b个词，后面看b个词（b在0-3之间随机）\n",
    "#min_count是对词进行过滤，频率小于min-count的单词则会被忽视，默认值为5。\n",
    "#negative和sample可根据训练结果进行微调，sample表示更高频率的词被随机下采样到所设置的阈值，默认值为1e-3,\n",
    "#negative: 如果>0,则会采用negativesamping，用于设置多少个noise words\n",
    "#hs=1表示层级softmax将会被使用，默认hs=0且negative不为0，则负采样将会被选择使用。\n",
    "#workers是线程数，此参数只有在安装了Cpython后才有效，否则只能使用单核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2823679386417206"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.wmdistance('','复华')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8a9911dd55824de2b9148872b09f5aa97429f0d8598f0eb95e15d199cda6b48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
